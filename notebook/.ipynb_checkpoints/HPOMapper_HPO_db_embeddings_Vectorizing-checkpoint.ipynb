{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661a903c-d7f9-4cf1-b986-771b7c4ac109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Import necessary libraries and modules\n",
    "# hpomapper: Extracting HPO Terms from Clinical Notes\n",
    "# ====================================================\n",
    "\n",
    "# This notebook demonstrates the full workflow of hpomapper:\n",
    "# 1. Setting up the environment\n",
    "# 2. Vectorizing the HPO database (if needed)\n",
    "# 3. Running hpomapper on clinical notes\n",
    "# 4. Analyzing and visualizing the results\n",
    "\n",
    "import os\n",
    "os.chdir(\"../src\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Add current directory to path to import hpomapper modules\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import hpomapper modules - make sure these match your actual file names\n",
    "from hpomapper_main import HPOVectorDB, BedrockLLM, hpomapper, parse_hpo_json\n",
    "from hpo_vectorization import HPOVectorizer, create_test_embeddings_file\n",
    "\n",
    "# Import AWS credential helper\n",
    "import aws_helper\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9996084-a97f-4300-8ce4-d58ab6ecf340",
   "metadata": {},
   "source": [
    "## 1. Setting up the environment\n",
    " First, let's make sure we have the necessary files and AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67467fb-4c7b-4c89-85f9-cc3c877e8cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:18:30,692 - aws_helper - INFO - Loaded configuration from ../config/hpomapper_config.yaml\n",
      "2025-03-30 17:18:30,694 - aws_helper - INFO - Using AWS profile from config: plm-dev\n",
      "2025-03-30 17:18:30,694 - aws_helper - INFO - Using AWS region from config: us-west-2\n",
      "2025-03-30 17:18:30,695 - aws_helper - INFO - Creating AWS session with profile: plm-dev\n",
      "2025-03-30 17:18:32,453 - aws_helper - INFO - AWS session created successfully. Using identity: arn:aws:sts::346034459362:assumed-role/AWSReservedSSO_CHLA_PowerUserAccess_f216beaca69a9496/hhakimjavadi@chla.usc.edu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AWS credentials verified successfully\n",
      "Account: 346034459362\n",
      "User: arn:aws:sts::346034459362:assumed-role/AWSReservedSSO_CHLA_PowerUserAccess_f216beaca69a9496/hhakimjavadi@chla.usc.edu\n",
      "✅ Bedrock client initialized successfully\n",
      "✅ HPO embeddings file found: ../db/G2GHPO_metadata_0.2k.npy\n",
      "✅ HPO JSON file found: ../db/hp.json\n",
      "Sample clinical notes file found: sample_clinical_notes.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Setting up the environment\n",
    "# ## 1. Setting up the environment\n",
    "# First, let's make sure we have the necessary files and AWS credentials\n",
    "\n",
    "# Check AWS credentials using the helper\n",
    "try:\n",
    "    # This will try to get a valid session, handling SSO if needed\n",
    "    aws_session = aws_helper.get_aws_session()\n",
    "    \n",
    "    # Test the session with a simple STS call\n",
    "    sts = aws_session.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    \n",
    "    print(f\"✅ AWS credentials verified successfully\")\n",
    "    print(f\"Account: {identity['Account']}\")\n",
    "    print(f\"User: {identity['Arn']}\")\n",
    "    \n",
    "    # Check Bedrock access\n",
    "    try:\n",
    "        bedrock = aws_session.client('bedrock-runtime')\n",
    "        print(f\"✅ Bedrock client initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Bedrock client initialization failed: {str(e)}\")\n",
    "        print(\"Make sure your AWS role has access to Bedrock\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ AWS credential check failed: {str(e)}\")\n",
    "    print(\"Please ensure your AWS SSO session is active:\")\n",
    "    print(\"  aws sso login --profile plm-dev\")\n",
    "    print(\"Or set environment variables:\")\n",
    "    print(\"  export AWS_PROFILE=plm-dev\")\n",
    "    print(\"  export AWS_DEFAULT_REGION=us-west-2\")\n",
    "\n",
    "# Check for HPO files\n",
    "hpo_embedding_file = '../db/G2GHPO_metadata_0.2k.npy'\n",
    "hpo_json_file = '../db/hp.json'\n",
    "\n",
    "if os.path.exists(hpo_embedding_file):\n",
    "    print(f\"✅ HPO embeddings file found: {hpo_embedding_file}\")\n",
    "else:\n",
    "    print(f\"⚠️ HPO embeddings file not found: {hpo_embedding_file}\")\n",
    "    print(\"   Vectorization will be required.\")\n",
    "\n",
    "if os.path.exists(hpo_json_file):\n",
    "    print(f\"✅ HPO JSON file found: {hpo_json_file}\")\n",
    "else:\n",
    "    print(f\"⚠️ HPO JSON file not found: {hpo_json_file}\")\n",
    "    print(\"   Please download it from https://hpo.jax.org/app/\")\n",
    "\n",
    "# Check for sample clinical notes\n",
    "sample_notes_file = 'sample_clinical_notes.csv'\n",
    "\n",
    "if not os.path.exists(sample_notes_file):\n",
    "    # Create a sample clinical notes file for demonstration\n",
    "    print(f\"Creating sample clinical notes file: {sample_notes_file}\")\n",
    "    \n",
    "    sample_notes = pd.DataFrame([\n",
    "        {\n",
    "            'patient_id': 'PT001',\n",
    "            'note': 'Patient presents with delayed motor development, hypotonia, and macrocephaly. MRI shows periventricular leukomalacia.'\n",
    "        },\n",
    "        {\n",
    "            'patient_id': 'PT002',\n",
    "            'note': 'A 5-year-old male with severe intellectual disability, epilepsy, and autistic features. He also has a history of recurrent respiratory infections.'\n",
    "        },\n",
    "        {\n",
    "            'patient_id': 'PT003',\n",
    "            'note': 'Adolescent female with short stature, bilateral cataracts, and sensorineural hearing loss. Family history of similar features in maternal lineage.'\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    sample_notes.to_csv(sample_notes_file, index=False)\n",
    "    print(f\"Created sample file with {len(sample_notes)} clinical notes\")\n",
    "else:\n",
    "    print(f\"Sample clinical notes file found: {sample_notes_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636fa1dc-4aab-40c6-b950-29cf7659e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:18:34,725 - aws_helper - INFO - Loaded configuration from ../config/hpomapper_config.yaml\n",
      "2025-03-30 17:18:34,726 - aws_helper - INFO - Using AWS profile from config: plm-dev\n",
      "2025-03-30 17:18:34,727 - aws_helper - INFO - Using AWS region from config: us-west-2\n",
      "2025-03-30 17:18:34,728 - aws_helper - INFO - Creating AWS session with profile: plm-dev\n",
      "2025-03-30 17:18:36,231 - aws_helper - INFO - AWS session created successfully. Using identity: arn:aws:sts::346034459362:assumed-role/AWSReservedSSO_CHLA_PowerUserAccess_f216beaca69a9496/hhakimjavadi@chla.usc.edu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing access to various AWS Bedrock models...\n",
      "\n",
      "== TESTING EMBEDDING MODELS ==\n",
      "\n",
      "Testing amazon.titan-embed-text-v2:0...\n",
      "✅ Successfully accessed amazon.titan-embed-text-v2:0\n",
      "   Embedding dimension: 512\n",
      "   Response keys: ['embedding', 'embeddingsByType', 'inputTextTokenCount']\n",
      "\n",
      "== TESTING LLM MODELS ==\n",
      "\n",
      "Testing anthropic.claude-v2:1...\n",
      "✅ Successfully accessed anthropic.claude-v2:1\n",
      "   Response: ' Hello!...'\n",
      "   Response time: 0.97s\n",
      "\n",
      "Testing anthropic.claude-3-5-sonnet-20241022-v2:0...\n",
      "✅ Successfully accessed anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "   Response: 'Hi there! How can I help you today?...'\n",
      "   Response time: 0.61s\n",
      "\n",
      "== RECOMMENDATIONS ==\n",
      "Based on the test results, update the hpomapper config to use:\n",
      "1. For LLM extraction: Use the working Claude model\n",
      "2. For embeddings: Use amazon.titan-embed-text-v2:0 with the correct format\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Test multiple embedding and LLM models\n",
    "import boto3\n",
    "import json\n",
    "import aws_helper\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get AWS session\n",
    "aws_session = aws_helper.get_aws_session()\n",
    "\n",
    "# Create bedrock-runtime client\n",
    "bedrock_runtime = aws_session.client('bedrock-runtime')\n",
    "\n",
    "print(\"Testing access to various AWS Bedrock models...\")\n",
    "\n",
    "# List of embedding models to test\n",
    "embedding_models = [\n",
    "    \"amazon.titan-embed-text-v2:0\"\n",
    "]\n",
    "\n",
    "# Test the embedding models\n",
    "print(\"\\n== TESTING EMBEDDING MODELS ==\")\n",
    "for model_id in embedding_models:\n",
    "    print(f\"\\nTesting {model_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # Use the correct format for Titan embed model\n",
    "        request_body = {\n",
    "            \"inputText\": \"Test input for embedding model\",\n",
    "            \"dimensions\": 512,\n",
    "            \"normalize\": True\n",
    "        }\n",
    "        \n",
    "        # Try to invoke the model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        \n",
    "        # Process the response\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        \n",
    "        if 'embedding' in response_body:\n",
    "            print(f\"✅ Successfully accessed {model_id}\")\n",
    "            print(f\"   Embedding dimension: {len(response_body['embedding'])}\")\n",
    "            print(f\"   Response keys: {list(response_body.keys())}\")\n",
    "        else:\n",
    "            print(f\"⚠️ Got response from {model_id}, but no embedding found\")\n",
    "            print(f\"   Response keys: {list(response_body.keys())}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error accessing {model_id}: {str(e)}\")\n",
    "\n",
    "# Test LLM models\n",
    "print(\"\\n== TESTING LLM MODELS ==\")\n",
    "\n",
    "# List of LLM models to test\n",
    "llm_models = [\n",
    "    {\"id\": \"anthropic.claude-v2:1\", \"name\": \"Claude v2.1\", \"type\": \"claude-v2\"},\n",
    "    {\"id\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\", \"name\": \"Claude 3.5 Sonnet\", \"type\": \"claude-3\"}\n",
    "]\n",
    "\n",
    "for model in llm_models:\n",
    "    model_id = model[\"id\"]\n",
    "    model_type = model[\"type\"]\n",
    "    print(f\"\\nTesting {model_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # Use the appropriate request format based on model type\n",
    "        if model_type == \"claude-3\":\n",
    "            # Format for Claude 3.x models (messages API)\n",
    "            request_body = {\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 200,\n",
    "                \"top_k\": 250,\n",
    "                \"stop_sequences\": [],\n",
    "                \"temperature\": 1,\n",
    "                \"top_p\": 0.999,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"hello world\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        elif model_type == \"claude-v2\":\n",
    "            # Format for Claude v2 models\n",
    "            request_body = {\n",
    "                \"prompt\": \"\\n\\nHuman: Hello world\\n\\nAssistant:\",\n",
    "                \"max_tokens_to_sample\": 300,\n",
    "                \"temperature\": 0.5,\n",
    "                \"top_k\": 250,\n",
    "                \"top_p\": 1,\n",
    "                \"stop_sequences\": [\"\\n\\nHuman:\"],\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "            }\n",
    "        elif model_type == \"llama\":\n",
    "            # Format for Llama models\n",
    "            request_body = {\n",
    "                \"prompt\": \"Hello world\",\n",
    "                \"max_gen_len\": 512,\n",
    "                \"temperature\": 0.5,\n",
    "                \"top_p\": 0.9\n",
    "            }\n",
    "        else:\n",
    "            # Generic format\n",
    "            request_body = {\n",
    "                \"inputText\": \"Hello world\",\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": 200,\n",
    "                    \"temperature\": 0.5,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Try to invoke the model\n",
    "        start_time = time.time()\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Process the response\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        \n",
    "        # Extract response text based on model type\n",
    "        response_text = None\n",
    "        if model_type == \"claude-3\" and \"content\" in response_body:\n",
    "            for content in response_body.get(\"content\", []):\n",
    "                if content.get(\"type\") == \"text\":\n",
    "                    response_text = content.get(\"text\", \"\")\n",
    "                    break\n",
    "        elif model_type == \"claude-v2\" and \"completion\" in response_body:\n",
    "            response_text = response_body.get(\"completion\", \"\")\n",
    "        elif model_type == \"llama\" and \"generation\" in response_body:\n",
    "            response_text = response_body.get(\"generation\", \"\")\n",
    "        \n",
    "        if response_text:\n",
    "            print(f\"✅ Successfully accessed {model_id}\")\n",
    "            print(f\"   Response: '{response_text[:50]}...'\")\n",
    "            print(f\"   Response time: {end_time - start_time:.2f}s\")\n",
    "        else:\n",
    "            print(f\"⚠️ Got response from {model_id}, but couldn't extract text\")\n",
    "            print(f\"   Response keys: {list(response_body.keys())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error accessing {model_id}: {str(e)}\")\n",
    "\n",
    "# Display the recommended approach based on available models\n",
    "print(\"\\n== RECOMMENDATIONS ==\")\n",
    "print(\"Based on the test results, update the hpomapper config to use:\")\n",
    "print(\"1. For LLM extraction: Use the working Claude model\")\n",
    "print(\"2. For embeddings: Use amazon.titan-embed-text-v2:0 with the correct format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3c391-b192-46b1-98ce-93e2eb592406",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Vectorizing the HPO database (if needed)\n",
    "If the HPO embeddings file is not available, we need to create it by vectorizing the HPO terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e13e077d-8ffb-4412-998f-49ad72eb2f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing HPO embeddings file: ../db/G2GHPO_metadata_0.2k.npy\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Vectorizing the HPO database (if needed)\n",
    "# ## 2. Vectorizing the HPO database (if needed)\n",
    "# If the HPO embeddings file is not available, we need to create it by vectorizing the HPO terms.\n",
    "\n",
    "# Check if vectorization is needed\n",
    "if not os.path.exists(hpo_embedding_file) and os.path.exists(hpo_json_file):\n",
    "    print(\"Vectorizing HPO database...\")\n",
    "    \n",
    "    # First, let's verify we can access the embedding model\n",
    "    try:\n",
    "        # Get AWS session\n",
    "        aws_session = aws_helper.get_aws_session()\n",
    "        \n",
    "        # Test access to the embedding model\n",
    "        model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "        print(f\"Testing access to {model_id}...\")\n",
    "        \n",
    "        # Create bedrock-runtime client\n",
    "        bedrock_runtime = aws_session.client('bedrock-runtime')\n",
    "        \n",
    "        # Simplified request format for Titan embed text v2\n",
    "        request_body = {\n",
    "            \"inputText\": \"Test input for embedding model\"\n",
    "        }\n",
    "        \n",
    "        # Try to invoke the model\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        \n",
    "        # If we get here, we have access\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        print(f\"✅ Successfully accessed {model_id}\")\n",
    "        print(f\"Embedding dimension: {len(response_body.get('embedding', []))}\")\n",
    "        \n",
    "        # Initialize the vectorizer with the working model\n",
    "        vectorizer = HPOVectorizer(\n",
    "            model_id=model_id  # Use the model we just verified\n",
    "        )\n",
    "        \n",
    "        # Parse HPO JSON\n",
    "        hpo_df = vectorizer.parse_hpo_json(hpo_json_file)\n",
    "        \n",
    "        # We'll use a small subset for demonstration\n",
    "        # In production, you'd use the full dataset\n",
    "        sample_size = min(200, len(hpo_df))  # Use up to 50 terms for test\n",
    "        sample_hpo_df = hpo_df.head(sample_size)\n",
    "        print(f\"Using {len(sample_hpo_df)} HPO terms for demonstration\")\n",
    "        \n",
    "        # Prepare data for vectorization\n",
    "        prepared_df = vectorizer.prepare_hpo_data(sample_hpo_df)\n",
    "        \n",
    "        # Generate embeddings (this will call the Bedrock API)\n",
    "        # This can take some time depending on the number of terms\n",
    "        with_embeddings_df = vectorizer.generate_embeddings(prepared_df)\n",
    "        \n",
    "        # Save embeddings\n",
    "        vectorizer.save_embeddings(with_embeddings_df, hpo_embedding_file)\n",
    "        \n",
    "        print(\"HPO vectorization completed with real embeddings\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with Bedrock API: {str(e)}\")\n",
    "        print(\"Creating test embeddings with mock data instead...\")\n",
    "        \n",
    "        # Create test embeddings file with mock data\n",
    "        create_test_embeddings_file(hpo_embedding_file, num_terms=50)\n",
    "        \n",
    "        print(\"Test HPO vectorization completed with mock embeddings\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Using existing HPO embeddings file: {hpo_embedding_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9439326-10c3-4767-be8f-c142c96c3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Create a function to debug embedding files\n",
    "def debug_embedding_file(embedding_file):\n",
    "    \"\"\"Display information about an embedding file for debugging\"\"\"\n",
    "    try:\n",
    "        import numpy as np\n",
    "        \n",
    "        # Load the embeddings file\n",
    "        data = np.load(embedding_file, allow_pickle=True).item()\n",
    "        \n",
    "        print(f\"Embedding file: {embedding_file}\")\n",
    "        print(f\"Model ID: {data.get('model_id', 'Unknown')}\")\n",
    "        print(f\"Created at: {data.get('created_at', 'Unknown')}\")\n",
    "        print(f\"Number of items: {len(data.get('items', []))}\")\n",
    "        \n",
    "        # Display info about the first item\n",
    "        if data.get('items', []):\n",
    "            first_item = data['items'][0]\n",
    "            print(\"\\nFirst item:\")\n",
    "            print(f\"  HPO ID: {first_item.get('hpo_id', 'Unknown')}\")\n",
    "            print(f\"  Name: {first_item.get('name', 'Unknown')}\")\n",
    "            \n",
    "            # Check embedding\n",
    "            if 'embedding' in first_item:\n",
    "                embedding = first_item['embedding']\n",
    "                print(f\"  Embedding shape: {embedding.shape}\")\n",
    "                print(f\"  Embedding type: {embedding.dtype}\")\n",
    "                print(f\"  Embedding preview: {embedding[:5]}...\")\n",
    "            else:\n",
    "                print(\"  No embedding found in item\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading embedding file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "026b5686-5ccf-4c3e-9da9-d200f3411766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file: ../db/G2GHPO_metadata_0.2k.npy\n",
      "Model ID: amazon.titan-embed-text-v2:0\n",
      "Created at: 2025-03-30 17:11:08\n",
      "Number of items: 200\n",
      "\n",
      "First item:\n",
      "  HPO ID: HP:0000001\n",
      "  Name: All\n",
      "  Embedding shape: (1024,)\n",
      "  Embedding type: float64\n",
      "  Embedding preview: [-0.06037616  0.01139749  0.0227799  -0.001469    0.06384783]...\n"
     ]
    }
   ],
   "source": [
    "debug_embedding_file(\"../db/G2GHPO_metadata_0.2k.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131b6f9-b063-4a21-992d-3a51a71ed60e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 6. Conclusion\n",
    "\n",
    "We've demonstrated the hpomapper workflow:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Vectorizing the HPO database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8a0ed-5950-4d7f-a152-9b01a701f05f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
